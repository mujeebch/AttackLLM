# AttackLLM
This repository has the extended version of the AttackLLM paper.

### AttackLLM: LLM-based Attack Pattern Generation for an Industrial Control System

**Author**: Chuadhry Mujeeb Ahmed  
**Contact**: mujeeb.ahmed@newcastle.ac.uk  
**Affiliation**: Newcastle University, UK

#### Abstract
Malicious examples are crucial for evaluating the robustness of machine learning algorithms under attack, particularly in Industrial Control Systems (ICS). However, collecting normal and attack data in ICS environments is challenging due to the scarcity of testbeds and the high cost of human expertise. Existing datasets are often limited by the domain expertise of practitioners, making the process costly and inefficient. The lack of comprehensive attack pattern data poses a significant problem for developing robust anomaly detection methods. This paper proposes a novel approach that combines data-centric and design-centric methodologies to generate attack patterns using large language models (LLMs). The results demonstrate that the attack patterns generated by LLMs surpass the quality and quantity of those created by human experts and offer a scalable solution that does not rely on expensive testbeds or pre-existing attack examples. This multi-agent based approach presents a promising avenue for enhancing the security and resilience of ICS environments.

#### Keywords
ICS, Attack Dataset, LLMs, CPS Security and Privacy

#### Introduction
Industrial Control Systems (ICS) form the backbone of numerous critical infrastructures (CI), including the electric power grid and water treatment facilities. These systems manage the physical operations within a CI through the use of computing and communication components such as Programmable Logic Controllers (PLCs), Supervisory Control and Data Acquisition (SCADA) systems, and communication networks. Although automation has streamlined the monitoring and control of these critical infrastructures, it has simultaneously made them vulnerable to potential threats from malicious actors, as evidenced by various attacks. The increasing frequency of attacks on ICS has spurred extensive research into security measures aimed at prevention, mitigation, and response. Prior research focuses on comprehensive testing of ICS security and the development of robust intrusion detection techniques. The success of these initiatives largely hinges on the systemâ€™s design and the availability of data, especially attack examples, obtained from critical infrastructures.

#### Methodology
This work presents a novel technique for the automatic generation of attacks based on both data and design principles, aimed at driving an ICS into an anomalous state. This resource is invaluable for encompassing a wide range of attack and anomaly scenarios. Agents powered by LLMs are employed to automatically identify attack patterns from historical ICS data. Traditionally, manually crafted attacks depend on human expertise to induce an anomalous state. By leveraging the pattern extraction capabilities of LLMs, expert-developed action sets designed to compromise system safety are analyzed, uncovering novel attack sequences from the data. This approach allows for the identification of previously unseen attacks and assessment of their impact, exploring numerous possibilities for disrupting a physical process and pinpointing combinations of sensors and actuators that can be manipulated to achieve this.

#### Case Study
The proposed approach is applied to a scaled-down version of a water treatment plant, known as the SWaT testbed, to generate attack patterns. The automated method produced a greater number of attack patterns compared to those generated manually by human experts. Experts familiar with the SWaT testbed designed a set of 36 attack scenarios across the plant by operating the system for five days. This achievement is significant given the limited research facilities and the scarcity of attack data. However, for machine learning algorithms that require large datasets, the available data is insufficient for training a robust supervised learning attack detection model. The attack patterns generated by AttackLLM were validated using three methods: (i) validating the normal patterns generated by AttackLLM and comparing them with the design specifications, (ii) comparing the attacks generated by AttackLLM with those created by human experts, and (iii) comparing the results between two different LLM Agents. These automatically generated attacks can serve as valuable resources for enhancing our understanding of potential threats and for developing effective attack detection strategies.

